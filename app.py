import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough

file_path = "rulebook.pdf" 
CHUNK_SIZE = 800
CHUNK_OVERLAP = 100
RETRIEVER_K = 50
GEMINI_MODEL = "gemini-2.5-flash"
EMBEDDING_MODEL = "models/text-embedding-004"

try:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
except KeyError:
    st.error("ì˜¤ë¥˜: Google API Keyê°€ Streamlit Secretsì— 'GOOGLE_API_KEY'ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def setup_rag_chain():
    st.write("ê·œì •ì§‘ì„ ì½ëŠ” ì¤‘...")
    try:
        loader = PyPDFLoader(file_path)
        documents = loader.load()
    except Exception as e:
        st.error(f"ì˜¤ë¥˜: PDF íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '{file_path}' íŒŒì¼ì´ GitHub ë£¨íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì—ëŸ¬: {e}")
        return None 

    st.write("AIê°€ ê·œì •ì§‘ì„ í•™ìŠµ ì¤‘...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
    chunks = text_splitter.split_documents(documents)
    
    embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
    vector_db = FAISS.from_documents(chunks, embeddings)
    
    retriever = vector_db.as_retriever(search_kwargs={"k": RETRIEVER_K})
    llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=0.1)
    
    prompt = ChatPromptTemplate.from_template("""
ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™:
ê·œì •ì§‘ ë‚´ì—ì„œ ì§ˆë¬¸ê³¼ 1%ë¼ë„ ê´€ë ¨ëœ ì¡°í•­, ë²Œì , ìƒì ì´ ì¡´ì¬í•˜ë©´ ë°˜ë“œì‹œ ëª¨ë‘ ì°¾ì•„ë‚´ê³  ì ˆëŒ€ ëˆ„ë½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.  
ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ì• ë§¤í•´ë„ 'ê´€ë ¨ ê°€ëŠ¥ì„±ì´ ì¡°ê¸ˆì´ë¼ë„ ìˆìœ¼ë©´' ë¬´ì¡°ê±´ ì œì‹œí•˜ì‹­ì‹œì˜¤.  
ê·œì •ì§‘ì—ì„œ ìˆ«ìë¥¼ ì°¾ì„ ìˆ˜ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ìˆ«ìë¥¼ ì œì‹œí•˜ì‹­ì‹œì˜¤.  
ìˆ«ìê°€ ëª…í™•í•˜ì§€ ì•Šì„ ë•Œë§Œ "ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¼ê³  í‘œì‹œí•©ë‹ˆë‹¤. ì¶”ì¸¡ì€ ê¸ˆì§€í•©ë‹ˆë‹¤.
        ê·œì • ë¬¸ì¥: {context}
        ì§ˆë¬¸: {question}
ì¶œë ¥ í˜•ì‹ ê·œì¹™(ê°•ì œ):
- ìµœëŒ€ 3ê°œì˜ í•­ëª©ì„ ì œì‹œí•˜ë˜, ê·œì •ì§‘ì—ì„œ ìˆ«ìê°€ ìˆëŠ” í•­ëª©ì„ ìµœìš°ì„ ì ìœ¼ë¡œ ì„ íƒí•˜ì‹­ì‹œì˜¤.
- ê° í•­ëª©ì€ ì•„ë˜ 3ì¤„ë§Œ í¬í•¨:
  1) ì¡°í•­: ì œ{ì¡°}ì¡° {ëª‡í•­}
  2) ê·œì •ë¬¸êµ¬: ë¬¸ì„œì˜ í•´ë‹¹ ë¬¸ì¥ì„ 15~30ì ì´ë‚´ë¡œ ìš”ì•½ ë˜ëŠ” ì¸ìš©
  3) ë²Œì /ìƒì  ìˆ«ì: ê·œì •ì§‘ì˜ í‘œÂ·ë¦¬ìŠ¤íŠ¸Â·ë²Œì í‘œÂ·ìƒì í‘œì— ìˆëŠ” ì •í™•í•œ ìˆ«ìë§Œ ê¸°ì…
     (ë¬¸ì„œì— ìˆ«ìê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì ê¸°, ì¡°ê¸ˆì´ë¼ë„ ê´€ë ¨ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì ê¸°)

ê²€ìƒ‰ ë° ì¶”ì¶œ ê¸°ì¤€:
- ì§ˆë¬¸ ë‚´ìš©ê³¼ ì§ì ‘ì  ë˜ëŠ” ê°„ì ‘ì  ê´€ë ¨ì´ ìˆëŠ” ì¡°í•­ì„ ëª¨ë‘ íƒìƒ‰í•˜ì‹­ì‹œì˜¤.
- ê´€ë ¨ë  ê°€ëŠ¥ì„±ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì„ íƒí•˜ì—¬ ìˆ«ìë¥¼ ì œì‹œí•˜ì‹­ì‹œì˜¤.
- ë¬¸ì„œ ë‚´ì—ì„œ ìˆ«ìê°€ ì¡´ì¬í•˜ë©´ ì ˆëŒ€ ìƒëµ ê¸ˆì§€.
- ê·œì •ì˜ í•œ í•­ëª©ì´ ì—¬ëŸ¬ í‘œì™€ ì—°ê²°ë  ê²½ìš°, ìˆ«ìê°€ ìˆëŠ” í‘œë¥¼ ìš°ì„  ì ìš©í•˜ì—¬ ì œì‹œ.

ì˜ˆì™¸ ì²˜ë¦¬:
- ê·œì •ì§‘ì— ì „í˜€ ìˆ«ìê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ "ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¡œ í‘œì‹œ.
- ê·œì •ì§‘ì— ì¡°í•­ì€ ìˆì§€ë§Œ ìˆ«ìê°€ ì—†ìœ¼ë©´ ì¡°í•­ì€ ì ê³  ìˆ«ìë§Œ "ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¼ê³  í‘œì‹œ.

ì´ ê·œì¹™ë“¤ì€ ì ˆëŒ€ì ìœ¼ë¡œ ìš°ì„  ì ìš©ë˜ë©°, ì‘ë‹µ í˜•ì‹ì„ ë³€ê²½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    """)
    
    chain = (
        RunnableParallel({"context": retriever, "question": RunnablePassthrough()})
        | prompt
        | llm
    )
    st.success("í•™ìŠµ ì™„ë£Œ!")
    return chain

# 3. Streamlit ì•± ì‹¤í–‰
st.title("ğŸ« ì •ë™ê³  í•™ìƒìƒí™œê·œì • ë„ìš°ë¯¸")
st.subheader("ê·œì •ì§‘ì„ í•™ìŠµí•œ ë„ìš°ë¯¸ì—ê²Œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”.")

rag_chain = None
with st.spinner("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤..."):
    rag_chain = setup_rag_chain()

if rag_chain:
    user_query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

    if user_query:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                answer = rag_chain.invoke(user_query)
                st.markdown("---")
                st.markdown(f"ë‹µë³€:")
                st.info(answer.content)
            except Exception as e:
                st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")







